proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=astro_cache:10m max_size=1g inactive=1y use_temp_path=off;

server {
    listen 80;
    server_name _;

    # Enable gzip compression for common text-based assets
    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    location / {
        # Forward requests to the Astro Node.js app
        proxy_pass http://app:4321;

        # Pass original request headers to the upstream app
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # Tell the app it's being served over HTTPS (hardcoded since Cloudflare terminates TLS)
        proxy_set_header X-Forwarded-Proto https;

        # Use the shared cache zone defined above
        proxy_cache astro_cache;

        # Cache key includes host + full URI (path + query string)
        # This ensures the warmer and real requests share the same cache entries
        proxy_cache_key "$host$request_uri";

        # Cache successful responses for up to 1 year
        # Actual freshness is controlled by Astro's Cache-Control headers (s-maxage=3600)
        proxy_cache_valid 200 1y;

        # Serve stale content if the upstream is slow or erroring
        # This keeps the site alive during revalidation or app restarts
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;

        # Revalidate stale cache entries in the background
        # The user gets the cached response immediately while Nginx fetches a fresh one
        proxy_cache_background_update on;

        # Prevent cache stampede: only one request goes upstream when cache is empty/stale
        proxy_cache_lock on;

        # Expose cache status in response headers for debugging (HIT, MISS, STALE, etc.)
        add_header X-Cache-Status $upstream_cache_status;
    }
}
